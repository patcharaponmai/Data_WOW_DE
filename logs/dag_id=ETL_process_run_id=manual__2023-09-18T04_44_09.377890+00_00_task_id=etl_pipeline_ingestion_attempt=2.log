d6943b0d3094
*** Found local files:
***   * /opt/airflow/logs/dag_id=ETL_process/run_id=manual__2023-09-18T04:44:09.377890+00:00/task_id=etl_pipeline_ingestion/attempt=2.log
[2023-09-18T05:00:48.885+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ETL_process.etl_pipeline_ingestion manual__2023-09-18T04:44:09.377890+00:00 [queued]>
[2023-09-18T05:00:48.890+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ETL_process.etl_pipeline_ingestion manual__2023-09-18T04:44:09.377890+00:00 [queued]>
[2023-09-18T05:00:48.890+0000] {taskinstance.py:1359} INFO - Starting attempt 2 of 2
[2023-09-18T05:00:48.896+0000] {taskinstance.py:1380} INFO - Executing <Task(PythonOperator): etl_pipeline_ingestion> on 2023-09-18 04:44:09.377890+00:00
[2023-09-18T05:00:48.901+0000] {standard_task_runner.py:57} INFO - Started process 2126 to run task
[2023-09-18T05:00:48.905+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'ETL_process', 'etl_pipeline_ingestion', 'manual__2023-09-18T04:44:09.377890+00:00', '--job-id', '555', '--raw', '--subdir', 'DAGS_FOLDER/data_pipeline.py', '--cfg-path', '/tmp/tmpks4kbne9']
[2023-09-18T05:00:48.906+0000] {standard_task_runner.py:85} INFO - Job 555: Subtask etl_pipeline_ingestion
[2023-09-18T05:00:48.940+0000] {task_command.py:415} INFO - Running <TaskInstance: ETL_process.etl_pipeline_ingestion manual__2023-09-18T04:44:09.377890+00:00 [running]> on host d6943b0d3094
[2023-09-18T05:00:49.005+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ETL_process' AIRFLOW_CTX_TASK_ID='etl_pipeline_ingestion' AIRFLOW_CTX_EXECUTION_DATE='2023-09-18T04:44:09.377890+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-09-18T04:44:09.377890+00:00'
[2023-09-18T05:00:49.009+0000] {logging_mixin.py:151} INFO - ########################
[2023-09-18T05:00:49.009+0000] {logging_mixin.py:151} INFO - ##### EXTRACT DATA #####
[2023-09-18T05:00:49.010+0000] {logging_mixin.py:151} INFO - ########################
[2023-09-18T05:00:49.010+0000] {logging_mixin.py:151} INFO - Start extracting data ...
[2023-09-18T05:00:49.010+0000] {logging_mixin.py:151} INFO - Listing parquet files in source file path ...
[2023-09-18T05:00:49.192+0000] {logging_mixin.py:151} INFO - READ FILE STATUS ------ [0/12960] ------
[2023-09-18T05:01:10.838+0000] {logging_mixin.py:151} INFO - read_and_concat_batch took 21.617910146713257 seconds to execute.
[2023-09-18T05:01:10.858+0000] {logging_mixin.py:151} INFO - READ FILE STATUS ------ [5000/12960] ------
[2023-09-18T05:01:40.231+0000] {logging_mixin.py:151} INFO - read_and_concat_batch took 29.35951828956604 seconds to execute.
[2023-09-18T05:01:40.271+0000] {logging_mixin.py:151} INFO - READ FILE STATUS ------ [10000/12960] ------
[2023-09-18T05:02:00.268+0000] {logging_mixin.py:151} INFO - read_and_concat_batch took 19.984731435775757 seconds to execute.
[2023-09-18T05:02:00.471+0000] {logging_mixin.py:151} INFO - Converting to Pandas DataFrame ...
[2023-09-18T05:02:54.162+0000] {logging_mixin.py:151} INFO - Data extraction complete
[2023-09-18T05:03:00.120+0000] {logging_mixin.py:151} INFO - extract_data took 131.1092779636383 seconds to execute.
[2023-09-18T05:03:00.124+0000] {logging_mixin.py:151} INFO - ########################
[2023-09-18T05:03:00.124+0000] {logging_mixin.py:151} INFO - #### TRANSFORM DATA ####
[2023-09-18T05:03:00.125+0000] {logging_mixin.py:151} INFO - ########################
[2023-09-18T05:03:00.126+0000] {logging_mixin.py:151} INFO - Converting create_at to Timestamp ...
[2023-09-18T05:03:13.362+0000] {logging_mixin.py:151} INFO - Converting product_expire to Timestamp ...
[2023-09-18T05:03:18.759+0000] {logging_mixin.py:151} INFO - =======================================
[2023-09-18T05:03:18.776+0000] {logging_mixin.py:151} INFO - Create csv file from filtered data ...
[2023-09-18T05:03:18.776+0000] {logging_mixin.py:151} INFO - =======================================
[2023-09-18T05:03:18.777+0000] {logging_mixin.py:151} INFO - Directory './data_sample/data_test/output_csv' already exists.
[2023-09-18T05:08:05.471+0000] {logging_mixin.py:151} INFO - transform_data took 305.33640217781067 seconds to execute.
[2023-09-18T05:08:05.487+0000] {logging_mixin.py:151} INFO - ====================================
[2023-09-18T05:08:05.487+0000] {logging_mixin.py:151} INFO - List columns for insert into target:
[2023-09-18T05:08:05.487+0000] {logging_mixin.py:151} INFO - ++++++++++++++++++++++++++++++++++
[2023-09-18T05:08:05.487+0000] {logging_mixin.py:151} INFO - "department_name", "sensor_serial", "create_at", "product_name", "product_expire"
[2023-09-18T05:08:05.488+0000] {logging_mixin.py:151} INFO - ====================================
[2023-09-18T05:08:05.490+0000] {logging_mixin.py:151} INFO - 
            COPY test_tbl_01("department_name", "sensor_serial", "create_at", "product_name", "product_expire")
            FROM stdin WITH CSV HEADER
            DELIMITER as ','
        
[2023-09-18T05:08:05.490+0000] {logging_mixin.py:151} INFO - ======== START INGEST DATA INTO CHILD TABLE `test_tbl_01` ========
[2023-09-18T05:08:05.545+0000] {postgres.py:168} INFO - Running copy expert: 
            COPY test_tbl_01("department_name", "sensor_serial", "create_at", "product_name", "product_expire")
            FROM stdin WITH CSV HEADER
            DELIMITER as ','
        , filename: ./data_sample/data_test/output_csv/data_date_2023-01-01.csv
[2023-09-18T05:08:05.675+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2023-09-18T05:08:15.266+0000] {logging_mixin.py:151} INFO - ======== FINISH INGEST DATA INTO CHILD TABLE `test_tbl_01` ========
[2023-09-18T05:08:15.271+0000] {logging_mixin.py:151} INFO - 
            COPY test_tbl_02("department_name", "sensor_serial", "create_at", "product_name", "product_expire")
            FROM stdin WITH CSV HEADER
            DELIMITER as ','
        
[2023-09-18T05:08:15.271+0000] {logging_mixin.py:151} INFO - ======== START INGEST DATA INTO CHILD TABLE `test_tbl_02` ========
[2023-09-18T05:08:15.289+0000] {postgres.py:168} INFO - Running copy expert: 
            COPY test_tbl_02("department_name", "sensor_serial", "create_at", "product_name", "product_expire")
            FROM stdin WITH CSV HEADER
            DELIMITER as ','
        , filename: ./data_sample/data_test/output_csv/data_date_2023-01-02.csv
[2023-09-18T05:08:15.325+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2023-09-18T05:08:25.936+0000] {logging_mixin.py:151} INFO - ======== FINISH INGEST DATA INTO CHILD TABLE `test_tbl_02` ========
[2023-09-18T05:08:25.939+0000] {logging_mixin.py:151} INFO - 
            COPY test_tbl_03("department_name", "sensor_serial", "create_at", "product_name", "product_expire")
            FROM stdin WITH CSV HEADER
            DELIMITER as ','
        
[2023-09-18T05:08:25.940+0000] {logging_mixin.py:151} INFO - ======== START INGEST DATA INTO CHILD TABLE `test_tbl_03` ========
[2023-09-18T05:08:25.953+0000] {postgres.py:168} INFO - Running copy expert: 
            COPY test_tbl_03("department_name", "sensor_serial", "create_at", "product_name", "product_expire")
            FROM stdin WITH CSV HEADER
            DELIMITER as ','
        , filename: ./data_sample/data_test/output_csv/data_date_2023-01-03.csv
[2023-09-18T05:08:25.975+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2023-09-18T05:08:39.662+0000] {logging_mixin.py:151} INFO - ======== FINISH INGEST DATA INTO CHILD TABLE `test_tbl_03` ========
[2023-09-18T05:08:39.669+0000] {logging_mixin.py:151} INFO - 
            COPY test_tbl_04("department_name", "sensor_serial", "create_at", "product_name", "product_expire")
            FROM stdin WITH CSV HEADER
            DELIMITER as ','
        
[2023-09-18T05:08:39.670+0000] {logging_mixin.py:151} INFO - ======== START INGEST DATA INTO CHILD TABLE `test_tbl_04` ========
[2023-09-18T05:08:39.710+0000] {postgres.py:168} INFO - Running copy expert: 
            COPY test_tbl_04("department_name", "sensor_serial", "create_at", "product_name", "product_expire")
            FROM stdin WITH CSV HEADER
            DELIMITER as ','
        , filename: ./data_sample/data_test/output_csv/data_date_2023-01-04.csv
[2023-09-18T05:08:39.862+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2023-09-18T05:09:03.701+0000] {logging_mixin.py:151} INFO - ======== FINISH INGEST DATA INTO CHILD TABLE `test_tbl_04` ========
[2023-09-18T05:09:03.791+0000] {logging_mixin.py:151} INFO - 
            COPY test_tbl_05("department_name", "sensor_serial", "create_at", "product_name", "product_expire")
            FROM stdin WITH CSV HEADER
            DELIMITER as ','
        
[2023-09-18T05:09:03.793+0000] {logging_mixin.py:151} INFO - ======== START INGEST DATA INTO CHILD TABLE `test_tbl_05` ========
[2023-09-18T05:09:03.921+0000] {postgres.py:168} INFO - Running copy expert: 
            COPY test_tbl_05("department_name", "sensor_serial", "create_at", "product_name", "product_expire")
            FROM stdin WITH CSV HEADER
            DELIMITER as ','
        , filename: ./data_sample/data_test/output_csv/data_date_2023-01-05.csv
[2023-09-18T05:09:04.148+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2023-09-18T05:09:23.344+0000] {logging_mixin.py:151} INFO - ======== FINISH INGEST DATA INTO CHILD TABLE `test_tbl_05` ========
[2023-09-18T05:09:23.353+0000] {logging_mixin.py:151} INFO - 
            COPY test_tbl_06("department_name", "sensor_serial", "create_at", "product_name", "product_expire")
            FROM stdin WITH CSV HEADER
            DELIMITER as ','
        
[2023-09-18T05:09:23.353+0000] {logging_mixin.py:151} INFO - ======== START INGEST DATA INTO CHILD TABLE `test_tbl_06` ========
[2023-09-18T05:09:23.391+0000] {postgres.py:168} INFO - Running copy expert: 
            COPY test_tbl_06("department_name", "sensor_serial", "create_at", "product_name", "product_expire")
            FROM stdin WITH CSV HEADER
            DELIMITER as ','
        , filename: ./data_sample/data_test/output_csv/data_date_2023-01-06.csv
[2023-09-18T05:09:23.435+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2023-09-18T05:09:50.098+0000] {logging_mixin.py:151} INFO - ======== FINISH INGEST DATA INTO CHILD TABLE `test_tbl_06` ========
[2023-09-18T05:09:50.137+0000] {logging_mixin.py:151} INFO - 
            COPY test_tbl_07("department_name", "sensor_serial", "create_at", "product_name", "product_expire")
            FROM stdin WITH CSV HEADER
            DELIMITER as ','
        
[2023-09-18T05:09:50.137+0000] {logging_mixin.py:151} INFO - ======== START INGEST DATA INTO CHILD TABLE `test_tbl_07` ========
[2023-09-18T05:09:50.171+0000] {postgres.py:168} INFO - Running copy expert: 
            COPY test_tbl_07("department_name", "sensor_serial", "create_at", "product_name", "product_expire")
            FROM stdin WITH CSV HEADER
            DELIMITER as ','
        , filename: ./data_sample/data_test/output_csv/data_date_2023-01-07.csv
[2023-09-18T05:09:50.311+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2023-09-18T05:10:15.827+0000] {logging_mixin.py:151} INFO - ======== FINISH INGEST DATA INTO CHILD TABLE `test_tbl_07` ========
[2023-09-18T05:10:15.934+0000] {logging_mixin.py:151} INFO - 
            COPY test_tbl_08("department_name", "sensor_serial", "create_at", "product_name", "product_expire")
            FROM stdin WITH CSV HEADER
            DELIMITER as ','
        
[2023-09-18T05:10:15.938+0000] {logging_mixin.py:151} INFO - ======== START INGEST DATA INTO CHILD TABLE `test_tbl_08` ========
[2023-09-18T05:10:16.069+0000] {postgres.py:168} INFO - Running copy expert: 
            COPY test_tbl_08("department_name", "sensor_serial", "create_at", "product_name", "product_expire")
            FROM stdin WITH CSV HEADER
            DELIMITER as ','
        , filename: ./data_sample/data_test/output_csv/data_date_2023-01-08.csv
[2023-09-18T05:10:16.571+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2023-09-18T05:10:48.993+0000] {logging_mixin.py:151} INFO - ======== FINISH INGEST DATA INTO CHILD TABLE `test_tbl_08` ========
[2023-09-18T05:10:49.055+0000] {logging_mixin.py:151} INFO - 
            COPY test_tbl_09("department_name", "sensor_serial", "create_at", "product_name", "product_expire")
            FROM stdin WITH CSV HEADER
            DELIMITER as ','
        
[2023-09-18T05:10:49.056+0000] {logging_mixin.py:151} INFO - ======== START INGEST DATA INTO CHILD TABLE `test_tbl_09` ========
[2023-09-18T05:10:49.089+0000] {postgres.py:168} INFO - Running copy expert: 
            COPY test_tbl_09("department_name", "sensor_serial", "create_at", "product_name", "product_expire")
            FROM stdin WITH CSV HEADER
            DELIMITER as ','
        , filename: ./data_sample/data_test/output_csv/data_date_2023-01-09.csv
[2023-09-18T05:10:49.375+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2023-09-18T05:11:26.835+0000] {logging_mixin.py:151} INFO - ======== FINISH INGEST DATA INTO CHILD TABLE `test_tbl_09` ========
[2023-09-18T05:11:26.979+0000] {logging_mixin.py:151} INFO - load_data took 201.49221634864807 seconds to execute.
[2023-09-18T05:11:27.033+0000] {python.py:194} INFO - Done. Returned value was: None
[2023-09-18T05:11:28.215+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=ETL_process, task_id=etl_pipeline_ingestion, execution_date=20230918T044409, start_date=20230918T050048, end_date=20230918T051128
[2023-09-18T05:11:29.562+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2023-09-18T05:11:30.341+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
